# awesome-training-free-methods
This is a repository to collect recent training-free algorithms, which can run on a low-end GPU card such as Tesla T4.

## Material Transfer

**ZeST: Zero-Shot Material Transfer from a Single Image.**<br>
*Ta-Ying Cheng, Prafull Sharma, Andrew Markham, Niki Trigoni, Varun Jampani.*<br>
arXiv 2024. [[PDF](https://arxiv.org/pdf/2404.06425)] [[Project](https://ttchengab.github.io/zest/)] [[Code]](https://github.com/ttchengab/zest_code)<br>

## Style Transfer

**Tuning-Free Adaptive Style Incorporation for Structure-Consistent Text-Driven Style Transfer.**<br>
*Yanqi Ge, Jiaqi Liu, Qingnan Fan, Xi Jiang, Ye Huang, Shuai Qin, Hong Gu, Wen Li, Lixin Duan.*<br>
arXiv 2024. [[PDF](https://arxiv.org/pdf/2404.06835.pdf)]<br>
Comments: It aims to achieve the style editing of the source image. Specifically, it divides the target prompt into a content prompt and style prompt, and then the cross-attention results of the two prompts are adaptively fused. Through this kind way, the proposed method could improve the style editing outcomes.

**Style Injection in Diffusion: A Training-free Approach for Adapting Large-scale Diffusion Models for Style Transfer.**<br>
*Jiwoo Chung, Sangeek Hyun, Jae-Pil Heo.*<br>
CVPR 2024. [[PDF](https://arxiv.org/pdf/2312.09008.pdf)] [[Project](https://jiwoogit.github.io/StyleID_site/)] [[Code]](https://github.com/jiwoogit/StyleID)<br>

## Image Manipulation

**Training-free Subject-Enhanced Attention Guidance for Compositional Text-to-image Generation.**<br>
*Shengyuan Liu, Bo Wang, Ye Ma, Te Yang, Xipeng Cao, Quan Chen, Han Li, Di Dong, Peng Jiang.*<br>
arXiv 2024. [[PDF](https://arxiv.org/pdf/2405.06948)]<br>

**ObjectAdd: Adding Objects into Image via a Training-Free Diffusion Modification Fashion.**<br>
*Ziyue Zhang, Mingbao Lin, Rongrong Ji.*<br>
arXiv 2024. [[PDF](https://arxiv.org/pdf/2404.17230)]<br>

**DemoFusion: Democratising High-Resolution Image Generation With No $$$.**<br>
*Ruoyi Du, Dongliang Chang, Timothy Hospedales, Yi-Zhe Song, Zhanyu Ma.*<br>
CVPR 2024. [[PDF](https://arxiv.org/pdf/2311.16973.pdf)] [[Project]](https://ruoyidu.github.io/demofusion/demofusion.html) [[Code]](https://github.com/PRIS-CV/DemoFusion)<br>

**HiDiffusion: Unlocking High-Resolution Creativity and Efficiency in Low-Resolution Trained Diffusion Models.**<br>
*Shen Zhang, Zhaowei Chen, Zhenyu Zhao, Zhenyuan Chen, Yao Tang, Yuhao Chen, Wengang Cao, Jiajun Liang.*<br>
arXiv 2024. [[PDF](https://arxiv.org/pdf/2311.17528.pdf)] [[Project]](https://hidiffusion.github.io/) [[Code]](https://github.com/megvii-research/HiDiffusion)<br>

**CutDiffusion: A Simple, Fast, Cheap, and Strong Diffusion Extrapolation Method.**<br>
*Mingbao Lin, Zhihang Lin, Wengyi Zhan, Liujuan Cao, Rongrong Ji.*<br>
arXiv 2024. [[PDF](https://arxiv.org/pdf/2404.15141.pdf)] [[Project]](https://github.com/lmbxmu/CutDiffusion)<br>

**FreeDiff: Progressive Frequency Truncation for Image Editing with Diffusion Models.**<br>
*Wei Wu, Qingnan Fan, Shuai Qin, Hong Gu, Ruoyu Zhao, Antoni B. Chan.*<br>
arXiv 2024. [[PDF](https://arxiv.org/pdf/2404.11895.pdf)] <br>

**Training-Free Consistent Text-to-Image Generation.**<br>
*Yoad Tewel, Omri Kaduri, Rinon Gal, Yoni Kasten, Lior Wolf, Gal Chechik, Yuval Atzmon.*<br>
arXiv 2024. [[PDF](https://arxiv.org/pdf/2402.03286.pdf)] [[Project]](https://consistory-paper.github.io/)<br>

**FouriScale: A Frequency Perspective on Training-Free High-Resolution Image Synthesis.**<br>
*Linjiang Huang, Rongyao Fang, Aiping Zhang, Guanglu Song, Si Liu, Yu Liu, Hongsheng Li.*<br>
arXiv 2024. [[PDF](https://arxiv.org/pdf/2403.12963.pdf)] [[Code]](https://github.com/LeonHLJ/FouriScale)<br>

**FreeControl: Training-Free Spatial Control of Any Text-to-Image Diffusion Model with Any Condition.**<br>
*Sicheng Mo, Fangzhou Mu, Kuan Heng Lin, Yanli Liu, Bochen Guan, Yin Li, Bolei Zhou.*<br>
CVPR 2024. [[PDF](https://arxiv.org/pdf/2312.07536.pdf)] [[Project](https://genforce.github.io/freecontrol/)] [[Code]](https://github.com/genforce/freecontrol)<br>

**Plug-and-Play Diffusion Features for Text-Driven Image-to-Image Translation.**<br>
*Narek Tumanyan, Michal Geyer, Shai Bagon, Tali Dekel.*<br>
CVPR 2023. [[PDF](https://arxiv.org/pdf/2211.12572.pdf)] [[Project](https://pnp-diffusion.github.io/)] [[Code]](https://github.com/MichalGeyer/plug-and-play)<br>

## Video Editing

**FLATTEN: optical FLow-guided ATTENtion for consistent text-to-video editing.**<br>
*Yuren Cong, Mengmeng Xu, Christian Simon, Shoufa Chen, Jiawei Ren, Yanping Xie, Juan-Manuel Perez-Rua, Bodo Rosenhahn, Tao Xiang, Sen He.*<br>
ICLR 2024. [[PDF](https://arxiv.org/pdf/2310.05922.pdf)] [[Project](https://flatten-video-editing.github.io/)] [[Code]](https://github.com/yrcong/flatten)<br>

**TokenFlow: Consistent Diffusion Features for Consistent Video Editing.**<br>
*Michal Geyer, Omer Bar-Tal, Shai Bagon, Tali Dekel.*<br>
ICLR 2024. [[PDF](https://arxiv.org/pdf/2307.10373.pdf)] [[Project](https://diffusion-tokenflow.github.io/)] [[Code]](https://github.com/omerbt/TokenFlow)<br>




